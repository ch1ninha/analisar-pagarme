{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Processando a informação da tabela<br>Declarações de bilios e cia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# tirar os avisos de quando 'mudar' o dataframe, para saber mais \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from babel.numbers import format_currency\n",
    "import json\n",
    "from datetime import date\n",
    "import csv\n",
    "import chardet\n",
    "import datetime\n",
    "import openpyxl\n",
    "\n",
    "# importando FROM THA HOUSE\n",
    "import horario\n",
    "import dataframe_customizado as df_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a variavel com o caminho do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\" # caminho que está nosso csv do pagar.me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÉTODOS/CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class DataframeClasse:\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        self._df = self.criar_df()\n",
    "        self.set_datas_datetime()\n",
    "        \n",
    "    # agora que temos o caminho para os dados, criamos o dataframe\n",
    "    def criar_df(self):\n",
    "        \"\"\"Durante a instancia, faz a criação do dataframe.\"\"\"\n",
    "        if \".csv\" in self.path:\n",
    "            with open(self.path,'rb') as file:\n",
    "                codificacao = chardet.detect(file.read())\n",
    "                tipo_codi = codificacao['encoding']\n",
    "            try:\n",
    "                self._df = pd.read_csv(self.path,encoding = tipo_codi)\n",
    "            except BaseException as err:\n",
    "                print(err)\n",
    "            return self._df\n",
    "        else:\n",
    "            print(\"Só suportamos arquivos .csv por enquanto\")\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self._df\n",
    "    \n",
    "    def set_df(self,df):\n",
    "        self._df = df\n",
    "        \n",
    "    def set_datas_datetime(self):\n",
    "        \"\"\"\n",
    "        Transformar as datas do dataframe no formato datetime.\n",
    "        \"\"\"\n",
    "        for cols in self._df.columns:\n",
    "            cond_cols = cols.upper()\n",
    "            if 'DATA' in cond_cols or 'DATE' in cond_cols:\n",
    "                try:\n",
    "                    self._df[cols] = pd.to_datetime(self._df[cols], format=\"%Y-%m-%d\", errors='ignore')\n",
    "                except BaseException as err:\n",
    "                    print(\"Checa se não existe nenhuma coluna que não é formato de data, mas em seu nome tem 'DATA' ou 'DATE'\")\n",
    "                    raise Exception(err)\n",
    "    \n",
    "    # gerando um dataframe com os valores como parametro\n",
    "    def get_df_valores(self,*valores):\n",
    "        \"\"\"\n",
    "        Cria um df somente com os valores que coloca como parametro.\n",
    "        Pode ser passado tanto como inteiros separados com virgula, como: get_df_valores(26, 8, 87)\n",
    "        Ou dentro de uma lista, ex: get_df_valores([10,13,80]).\n",
    "        \"\"\"\n",
    "        if len(valores) == 0:\n",
    "            raise Exception(\n",
    "                    \"\"\"Não esqueça de passar os valores como parâmetro. Ex: <ObjetoClasse>.get_df_valores(valores)\n",
    "                     Rode a expressão '<ObjetoClasse>.get_df_valores.__doc__' para ver a documentacao do método.\n",
    "                    \"\"\")\n",
    "        \n",
    "        _lista_strings = []\n",
    "        _string_filter = ''\n",
    "\n",
    "        # pegando os valores no parametro e criando uma string com eles\n",
    "        for val in valores:\n",
    "            # checa se não foi passado em uma lista, se for pega a primeira\n",
    "            if type(valores[0]) == list:\n",
    "                for list_valores in val:\n",
    "                    _lista_strings.append(f\"(self._df['valor_brl'] == {list_valores})\")\n",
    "            # se nao for lista, roda o loop normal com os valores\n",
    "            else:\n",
    "                _lista_strings.append(f\"(self._df['valor_brl'] == {val})\")\n",
    "\n",
    "        # juntando numa string, é os parametros para o filtro. | => or\n",
    "        _string_filter = \" | \".join(_lista_strings)\n",
    "        # agora juntamos na expressão que vamos usar\n",
    "        _string_resultado = f\"self._df[{_string_filter}]\"\n",
    "\n",
    "        # roda a string como uma expressão lida como código\n",
    "        return eval(_string_resultado)\n",
    "    \n",
    "\n",
    "    \n",
    "    # métodos não essenciais\n",
    "    def get_colunas(self,opcao = None):\n",
    "        \"\"\"\n",
    "        Devolve as colunas do dataframe, se quiser mostra tbm o indice\n",
    "        de cada com seu nome. 'S' para Sim e 'N' para Não\n",
    "        \"\"\"\n",
    "        \n",
    "        # se n quiser, só retorna as colunas do dataframe\n",
    "        _cond2 = str(opcao).upper().startswith(\"N\")\n",
    "        if None or _cond2:\n",
    "            return self._df.columns\n",
    "        \n",
    "        elif \"oi\" in opcao:\n",
    "            print(\"olá\")\n",
    "            \n",
    "        # se voce quiser, printa as colunas do dataframe tbm\n",
    "        else:\n",
    "            print(\"     Indice | Nome Coluna\")\n",
    "            print(\"------------------------------\")\n",
    "            for n,cols in enumerate(self._df.columns):\n",
    "                print(\"| {:2} |  {:20} |\".format(n,cols))\n",
    "            print(\"------------------------------\")\n",
    "            return self._df.columns\n",
    "    \n",
    "    # Datas\n",
    "    def get_intervalo_datas(self):\n",
    "        _data_MAX = max(self._df['data_criacao'])\n",
    "        _data_MIN = min(self._df['data_criacao'])\n",
    "        print(\"Diferença de: {}\".format((_data_MAX - _data_MIN)))\n",
    "        print(\"Entre o dia {} e o dia {}\".format(_data_MIN.date(),_data_MAX.date()))\n",
    "        return _data_MAX - _data_MIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe para o dataframe do EadBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class DataFrame_eadbox(DataframeClasse):\n",
    "    def __init__(self,path):\n",
    "        super().__init__(path)\n",
    "        self.set_colunas_eadbox()\n",
    "        \n",
    "    \"\"\" \n",
    "    When started, this is instantiated:   \n",
    "        self.path = path\n",
    "        self._df = self.criar_df()\n",
    "        self.set_datas_datetime()\n",
    "        \n",
    "        get_df() -> returning the <instance>.dataframe\n",
    "        set_df() -> setting the new df to <instance>.dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def set_colunas_eadbox(self):\n",
    "        list_col_original = [_ for _ in self.get_df().columns]\n",
    "        list_col_changed = ['nome','email','cidade','estado','produto_tipo',\n",
    "                            'produto_titulo','campanha_titulo','metodo_pag',\n",
    "                            'cupom','status_detalhado','info_extra','status',\n",
    "                            'valor_brl','data_criacao','data_atualizacao']\n",
    "        dic_cols_mudar = {ori:chan for (ori,chan) in zip(list_col_original,list_col_changed)}\n",
    "        _cond = self.get_df().rename(columns=dic_cols_mudar)\n",
    "        self.set_df(_cond)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Pagar.me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciando a classe e checando o dataframe\n",
    "obj_df = DataframeClasse(path)\n",
    "\n",
    "# passamos o dataframe do obj para a variavel df, não é uma copia dela, referencia a propria do objeto\n",
    "df = obj_df.get_df()\n",
    "df_copy = df.copy()\n",
    "\n",
    "# observamos as colunas do dataframe\n",
    "obj_df.get_colunas(\"s\")\n",
    "print()\n",
    "\n",
    "# retornar um dataframe com o status como PAGO, e sem algum valor estornado\n",
    "df_status_pago = df[(df['status'] == 'paid') & (df['valor_estornado_brl'] <= 0)]\n",
    "\n",
    "# ordenar o dataframe pela data de atualização\n",
    "df_status_pago = df_status_pago.sort_values(by=['data_atualizacao'], ascending=False)\n",
    "\n",
    "# objetivo é devolver o obj com nosso dataframe e ja puxando um com transacoes realmente pagas/ativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos \"Splitar\" o dataframe em dois, com os assinantes e outro com planos => sendo considerado o 'valor_brl' para divisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deixando a data em formato datetime64 ns, ao inves de ns UTC\n",
    "df_status_pago['data_atualizacao'] = pd.to_datetime(df_status_pago.data_atualizacao).dt.tz_localize(None)\n",
    "\n",
    "# tirando as duplicadas do df_status_pago\n",
    "df_pago_unico = df_status_pago.drop_duplicates(subset=['email','valor_brl'], keep='first')\n",
    "\n",
    "print(\"Emails duplicados: {}\".format(sum([_ for _ in df_pago_unico['email'].value_counts() if _ > 1])))\n",
    "\n",
    "# desde qual dia é para puxar?\n",
    "print(\"Desde que dia é para filtrar?\")\n",
    "ano, mes, dia = horario.get_data_separada()\n",
    "\n",
    "# criando um dataframe com valores unicos usando data como parametro\n",
    "df_pagamentos_unicos = df_pago_unico[(df_pago_unico['data_atualizacao'] > (pd.Timestamp(year=ano,month=mes,day=dia,\n",
    "                                                                                        hour=0).to_datetime64()))]\n",
    "\n",
    "print()\n",
    "print(\"Pagantes únicos desde o dia {:02d}/{:02d}/{}\".format(dia,mes,ano))\n",
    "print(df_pagamentos_unicos['valor_brl'].value_counts())\n",
    "\n",
    "# objetivo, fazer analise por periodo (checar), mudar a data para conseguirmos tratar e criacao do df com pag únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando os valore que possuem subscription id\n",
    "lista_valores_subs = [100]\n",
    "for valor,qtde in df_status_pago[df_status_pago['subscription_id'] != 'None']['valor_brl'].value_counts().items():\n",
    "    print(\"R$ {:,} | {}\".format(valor,qtde))\n",
    "    \n",
    "print()\n",
    "# tirando o subscription_id do 1992\n",
    "df_status_pago.loc[df_status_pago['valor_brl'] == 1992, ['subscription_id']] = \"None\"\n",
    "print(\"Depois de deixar o valor de 1992.0 sem nenhum subscription_id\")\n",
    "for valor,qtde in df_status_pago[df_status_pago['subscription_id'] != 'None']['valor_brl'].value_counts().items():\n",
    "    lista_valores_subs.append(valor)\n",
    "    print(\"R$ {:,} | {}\".format(valor,qtde))\n",
    "    \n",
    "print()\n",
    "\n",
    "lista_valores_resto = []\n",
    "for valores,i in df['valor_brl'].value_counts().items():\n",
    "    if valores not in lista_valores_subs:\n",
    "        lista_valores_resto.append(valores)\n",
    "        \n",
    "print(\"lista com valores da assinatura: {}\".format(lista_valores_subs))\n",
    "print(\"lista com o resto: {}\".format(lista_valores_resto))\n",
    "# obj, conseguimos a lista com os valores que vamos usar para dividir o df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### celula que fazemos a separação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passar os valores que possuem o subscription_id\n",
    "\n",
    "# passamos o dataframe com valores pago como atributo\n",
    "obj_df.set_df(df_status_pago)\n",
    "print(\"Tamanho df_status_pago: {}\".format(len(obj_df.get_df())))\n",
    "df_subscribers = obj_df.get_df_valores(lista_valores_subs)\n",
    "df_plans = obj_df.get_df_valores(lista_valores_resto)\n",
    "\n",
    "print(\"{}\\n{:{}} +\\n---\\n{}\\n\".format(len(df_subscribers),len(df_plans), len(str(len(df_plans)))+1, len(df_subscribers) + len(df_plans)))\n",
    "print(df_subscribers['valor_brl'].value_counts())\n",
    "print(df_plans['valor_brl'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df_subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As are recurring payments, we want the active students\n",
    "# Who made a payment on the last 30 days, so its a active student.\n",
    "# So we make a filter on dataframe selecting the last 30 days (1 month)\n",
    "\n",
    "df_subscribers.sort_values(by=['data_atualizacao'], ascending=False, inplace=True)\n",
    "df_subscribers.drop_duplicates(subset=['email','valor_brl'],inplace=True)\n",
    "\n",
    "# creating variables to filter the dataframe, default = 1 month (30 days)\n",
    "period_filter = datetime.datetime.now() - datetime.timedelta(days=30)\n",
    "\n",
    "_year_filter = period_filter.year\n",
    "_month_filter = period_filter.month\n",
    "_day_filter = period_filter.day\n",
    "\n",
    "# now make the filter\n",
    "df_subscribe_filtered = df_subscribers[(df_subscribers['data_atualizacao'] > (pd.Timestamp(\n",
    "                                                        year=_year_filter,month=_month_filter,\n",
    "                                                        day=_day_filter,hour=0).to_datetime64()))]\n",
    "                                                        # end the expression of filter\n",
    "# --\n",
    "\n",
    "df_subs_filt_active = df_subscribe_filtered.filter(items=['id','valor_brl']).groupby(by='valor_brl').count()\n",
    "df_subs_filt_active.rename(columns={\"id\":\"Alunos Ativos\"},inplace=True)\n",
    "df_subs_filt_active['Faturamento'] = df_subs_filt_active.index * df_subs_filt_active['Alunos Ativos']\n",
    "print(\"Total: R$ {}\".format(df_subs_filt_active['Faturamento'].sum()))\n",
    "df_subs_filt_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando os valores por dia\n",
    "\n",
    "df_fil_subs = df_subscribe_filtered.filter(items=['valor_brl','data_atualizacao'])\n",
    "df_subs_value = df_fil_subs['valor_brl']\n",
    "df_subs_date = df_fil_subs['data_atualizacao']\n",
    "\n",
    "\n",
    "l_valor = list()\n",
    "l_date = list()\n",
    "dic_value_date_subs = dict()\n",
    "\n",
    "c = 0\n",
    "for v,d in zip(df_subs_value,df_subs_date):\n",
    "    d = str(d.date())\n",
    "    #l_date.append(d)\n",
    "    #l_valor.append(v)\n",
    "    \n",
    "    if d not in dic_value_date_subs:\n",
    "        dic_value_date_subs[d] = 0\n",
    "    dic_value_date_subs[d] += v\n",
    "\n",
    "# print(l_date)\n",
    "# print(l_valor)\n",
    "dic_value_date_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_plans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plans.groupby(by='valor_brl').count()\n",
    "\n",
    "df_plans_active = df_plans[df_plans['subscription_id'] == \"None\"].filter(items=['id','valor_brl']).groupby(by='valor_brl').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plans_date = df_custom.get_date_filter(df_plans,\"2022-03-01\",\"2022-03-14\")\n",
    "\n",
    "df_plans_filter = df_plans_date.filter(items=['valor_brl','valor_captura_brl']).groupby(by=\"valor_brl\").count()\n",
    "df_plans_filter['Faturado'] = df_plans_filter.index * df_plans_filter['valor_captura_brl']\n",
    "print(\"Total: R$ {}\".format(df_plans_filter['Faturado'].sum()))\n",
    "df_plans_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pegando os valores por dia\n",
    "\n",
    "df_fil_plans = df_plans_date.filter(items=['valor_brl','data_atualizacao'])\n",
    "df_plans_value = df_fil_plans['valor_brl']\n",
    "df_plans_date = df_fil_plans['data_atualizacao']\n",
    "\n",
    "\n",
    "l_valor = list()\n",
    "l_date = list()\n",
    "dic_value_date_plans = dict()\n",
    "\n",
    "c = 0\n",
    "for v,d in zip(df_plans_value,df_plans_date):\n",
    "    d = str(d.date())\n",
    "    \n",
    "    if d not in dic_value_date_plans:\n",
    "        dic_value_date_plans[d] = 0\n",
    "    dic_value_date_plans[d] += v\n",
    "\n",
    "dic_value_date_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df_custom.get_date_filter(df_status_pago,\"2022-02-10\",\"2022-03-10\")\n",
    "print(f\"Data Maxima: {check['data_atualizacao'].max()}\")\n",
    "print(f\"Data Minima: {check['data_atualizacao'].min()}\")\n",
    "\n",
    "check['valor_brl'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando lista de compradores e checando com ultimos pagamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ate_ontem = df_custom.get_date_filter(df_status_pago, \"2021-10-20\",\"2022-03-15\")\n",
    "\n",
    "lista_compradores_ontem = df_custom.get_lista_email(df_ate_ontem)\n",
    "\n",
    "\n",
    "df_ate_hoje = df_custom.get_date_filter(df_status_pago,\"2022-03-15\")\n",
    "\n",
    "print(\"Até ontem: {}\".format(len(df_ate_ontem)))\n",
    "print(\"Status Pago: {}\".format(len(df_status_pago)))\n",
    "print(\"Lista compradores: {}\".format(len(lista_compradores_ontem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ate_hoje['valor_brl'].value_counts()\n",
    "c = 0\n",
    "l = []\n",
    "l_novo = []\n",
    "for email_hoje in df_ate_hoje['email']:\n",
    "    if email_hoje in lista_compradores_ontem:\n",
    "        print(\"Email => {}, já estava na lista de compradores\".format(email_hoje))\n",
    "        l.append(email_hoje)\n",
    "        c += 1\n",
    "    else:\n",
    "        novo_valor = df_ate_hoje[df_ate_hoje['email']==email_hoje]['valor_brl']\n",
    "        l_novo.append(novo_valor)\n",
    "print()        \n",
    "print(f\"Dos {len(df_ate_hoje['email'])} pagamentos de hoje para ontem, apenas {c} já eram pagantes\")\n",
    "print()\n",
    "print(\"Dos novos pagantes, são esses valores\")\n",
    "\n",
    "#print(l_novo)\n",
    "l_nn = []\n",
    "for i in l_novo:\n",
    "    l_nn.append(i.values.item())\n",
    "    \n",
    "contg_pagamentos = Counter(l_nn)\n",
    "for v,q in contg_pagamentos.items():\n",
    "    print(f\"No valor de R$ {v} foram {q} novos pagantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_pago.sort_values(by='data_atualizacao', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPRADORES COM PAGAMENTO DUPLO, (EMAIL IGUAL | VALOR DIFERENTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t = df_pago_unico[df_pago_unico.duplicated(subset='email', keep=False)].sort_values(by=['email','data_atualizacao'])\n",
    "#pd.set_option('display.max_rows', None)\n",
    "d_t['valor_brl'].value_counts()\n",
    "d_first = d_t.drop_duplicates(subset=['email'],keep='first')\n",
    "d_last = d_t.drop_duplicates(subset=['email'],keep='last')\n",
    "d_first.head()\n",
    "print(f\"Do dia {d_t['data_atualizacao'].min().date()} ate {d_t['data_atualizacao'].max().date()}\")\n",
    "print(\"Compradores com ultima ação sendo COMPRA, que fizeram +1 pedido com diferentes valores e mesmo email\")\n",
    "print(\"{} compradores\".format(len(d_first)))\n",
    "print()\n",
    "print(\"Os valores da primeira compra são:\")\n",
    "print(\"Qtde -> valor\")\n",
    "for v,q in d_first['valor_brl'].value_counts().items():\n",
    "    print(\"{:2} -> R$ {:,}\".format(q,v))\n",
    "\n",
    "print()\n",
    "print(\"Quantia de valores ref a segunda compra\")\n",
    "print(\"Qtde -> valor\")\n",
    "for v,q in d_last['valor_brl'].value_counts().items():\n",
    "    print(\"{:2} -> R$ {:,}\".format(q,v))\n",
    "    \n",
    "c = 0\n",
    "temp_medio = 0\n",
    "for tempo_f,tempo_l in zip(d_first['data_atualizacao'],d_last['data_atualizacao']):\n",
    "    #if tempo_l - tempo_f > datetime.timedelta(seconds=1800):\n",
    "    temp_medio += (tempo_l-tempo_f).total_seconds()\n",
    "        #print(temp_medio / 3600)\n",
    "        #c += 1\n",
    "\n",
    "print()\n",
    "print(\"Com um tempo médio da primeira compra para a segunda de aproximadamente {}\".format(datetime.timedelta(seconds= (temp_medio / len(d_last)))))\n",
    "print(d_t['data_atualizacao'].min().date())\n",
    "# mudando o tipo das datas para exportar como .xlsx\n",
    "d_t['data_criacao'] = pd.to_datetime(d_t.data_criacao).dt.tz_localize(None)\n",
    "d_t['data_atualizacao'] = pd.to_datetime(d_t.data_atualizacao).dt.tz_localize(None)\n",
    "d_t.to_excel(\"dados\\tabela_duplicados.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contagem dos valores que possuem um subscription_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pegando a quantidade de alunos, manipulando o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos já usar como base o df com somente transacoes pagas/nao canceladas\n",
    "df_assinantes = df_status_pago.copy()\n",
    "\n",
    "# vamos montar uma lista com os id_subscription com o valor 1992\n",
    "lista_subscription_id_1992 = list()\n",
    "for i in df_assinantes[(df_assinantes['valor_brl'] == 1992.0) & (df_assinantes['subscription_id'] != 'None')]['subscription_id']:\n",
    "    lista_subscription_id_1992.append(i)\n",
    "\n",
    "# agora arrumamos os 'subscription_id' em transacoes que nao era para ter. estava em valores pagos a vista\n",
    "df_assinantes['subscription_id'] = df_assinantes['subscription_id'].replace(lista_subscription_id_1992, 'None')\n",
    "\n",
    "# checando oq comentamos acima\n",
    "# print(\"--- Com subscription_id ---\")\n",
    "# print(df_assinantes[(df_assinantes['subscription_id'] != \"None\")]['valor_brl'].value_counts())\n",
    "# print(\"\\n--- Sem subscription_id ---\")\n",
    "# print(df_assinantes[(df_assinantes['subscription_id'] == \"None\")]['valor_brl'].value_counts())\n",
    "\n",
    "\n",
    "# tem valores que seriam de subscription_id que não possuem um subs_id\n",
    "df_assinantes[ (df_assinantes['valor_brl'] == 399) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando os outros valores com subscription ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_pago[(df_status_pago['subscription_id'] != \"None\")]['valor_brl'].value_counts()\n",
    "\n",
    "df[(df['valor_brl']==1992) & (df['subscription_id'] != \"None\")]['subscription_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGORA VER TODOS OS VALORES\n",
    "print(\"-- Valores que deveriam ter o subscription ID, mas não possuem -- \")\n",
    "valores = [200, 242, 399, 139, 79]\n",
    "\n",
    "for val in valores:\n",
    "    qtde = sum([v for k,v in df_status_pago[(df_status_pago['valor_brl'] == val)]['subscription_id'].value_counts().items() if k == \"None\"])\n",
    "    print(\"| De R$ {}: {}\".format(val,qtde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Média das parcelas com transacoes com subscription_id == 'None'\")\n",
    "\n",
    "valores = [200, 242, 399, 139, 79]\n",
    "\n",
    "for val in valores:\n",
    "    qtde = df_status_pago[(df_status_pago['valor_brl'] == val) & (df_status_pago['subscription_id'] == 'None')]['num_parcelas']\n",
    "    print(\"Média de parcelas no valor de R$ {}: {}\".format(val, qtde.sum() / len(qtde)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_none_1992 = df_status_pago[(df_status_pago['valor_brl'] == 1992) & (df_status_pago['subscription_id'] == 'None')]['num_parcelas']\n",
    "df_notNone_1992 = df_status_pago[(df_status_pago['valor_brl'] == 1992) & (df_status_pago['subscription_id'] != 'None')]['num_parcelas']\n",
    "print(\"Média de parcelas no valor de R$ 1992 (None): {}\".format(df_none_1992.sum() / len(df_none_1992)))\n",
    "print(\"Média de parcelas no valor de R$ 1992 (not None): {}\".format(df_notNone_1992.sum() / len(df_notNone_1992)))\n",
    "print(\"Com none: {}\".format(len(df_none_1992)))\n",
    "print(\"Sem none: {}\".format(len(df_notNone_1992)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vezes que o email repete | Número de vezes que essa quantia repete\")\n",
    "for i in Counter(df['email'].value_counts()).items():\n",
    "    print(\"Qtde: {:2} | Ocorrencias: {}\".format(i[0],i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionar só a primeira linha\n",
    "df.loc[[1],]\n",
    "\n",
    "# retornar um dataframe com os EMAILS duplicados\n",
    "#df_email_duplicado = df[(df.duplicated(['email'])) & (df['status'] == 'paid')]\n",
    "#df_email_duplicado = df[(df.duplicated(['email']))]\n",
    "\n",
    "# COM VALORES PAGO\n",
    "df_email_duplicado = df_status_pago[(df_status_pago.duplicated(['email'])) & (df_status_pago['status'] == 'paid')]\n",
    "#df_email_duplicado = df_status_pago[(df_status_pago.duplicated(['email']))]\n",
    "\n",
    "# printar\n",
    "print(\"Colunas: {}\".format(len(df_email_duplicado)))\n",
    "df_email_duplicado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
